<!DOCTYPE HTML>
<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
    <title>Loops</title>
    <link rel="stylesheet" href="github-markdown.css">
    <style>
      body {
        box-sizing: border-box;
        min-width: 200px;
        max-width: 980px;
        margin: 0 auto;
        padding: 45px;
      }
    </style>
</head>
<body >
  <article class="markdown-body">
      <p align="center">
        <h1>Advices to run computations on big image data.</h1>
        </p>
      <p><nav>
       <a href="index.html"> Main page</a>&bull;
        <a href="mlseminar.html">Teaching</a>&bull;
        <a href="research.html">Research</a>&bull;
        <a href="activism.html">Activism</a>&bull;
        <a href="talks.html">Talks</a>&bull;
        <a href="tec.html">Experiments with technology</a>&bull;
        <a href="tutoring.html">Tutoring</a>&bull;
        <a href="bm.html">Books and movies</a>&bull;
      </nav></p>

 <p class="aligncenter">
    <img src='img/eagle.gif' title="Yonsei's eagle generated by a GAN" alt="Yonsei's eagle generated by a GAN" />
    <img src='img/eagle2.gif' title="Yonsei's eagle generated by a GAN" alt="Yonsei's eagle generated by a GAN" />      
</p>

<hr>      
<p>




Most python tutorials explain that if you need to create a list, <a href="https://www.python.org/dev/peps/pep-0202/">list comprehensions</a> are faster than for loops.
<pre>
import timeit

s='''iterations = 100
newlist = []
for i in range(iterations):
    newlist.append(i+1)'''
timeit.timeit(s)
8.76447730000001    
</pre>
Compared with 

<pre>
s2='''iterations = 100
newlist = [i+1 for i in range(iterations)]'''
timeit.timeit(s2)
4.8245505000000435    
</pre>
Now, assume that the objects on the list are all possible combinations of two processes on images (perhaps this is a grid search for optimal parameters). 
Let's say 

<pre>
def P(X,a):
    #X is the image
    #a is a parameter to test
def Q(Y,b):
    #Y is the output of P(X,a)
    #b is a parameter to test
X = some image
values = [Q(P(X,a),b) for a in P_parameters for b in Q_parameters]
</pre>


    
Note that you compute 'P(X,a)' several times. You may assume that the speed improvement of the list comprehension is worth repeating a computation, but in the following example, we see that there is not even a speed improvement:
<pre>import timeit
s='''
from PIL import Image
img = Image.effect_noise((128,128), 64)
base_img = Image.effect_noise((128,128), 32)
base2_img = Image.effect_noise((128,128), 128)
listimages=[]
for value in range(100):
    imgt = Image.blend(img, base_img, value/110)
    for value2 in range(100):
        endvalue = Image.blend(imgt, base2_img, value2/110)
        listimages.append(endvalue)
'''

s2='''
from PIL import Image
img = Image.effect_noise((128,128), 64)
base_img = Image.effect_noise((128,128), 32)
base2_img = Image.effect_noise((128,128), 128)
otherlist = [Image.blend(Image.blend(img, base_img, value/110), base2_img, value2/110) for value in range(100) for value2 in range(100) ]'''

timeit.timeit(stmt=s, number=10)
3.420247700000118

timeit.timeit(stmt=s2, number=10)
5.474881500000038
</pre>

This is an abstract example, but in Machine Learning/Computer Vision you may have a similar process with other operations such as rotation or resizing.
</p><p>

Here is another example of optimization, this one is from <a href='https://wiki.python.org/moin/PythonSpeed/PerformanceTips'> Python Performance tips </a href>.

<pre>
newlist = []
for word in oldlist:
    newlist.append(word.upper()) 
</pre>

<q>Suppose you can't use map or a list comprehension? You may be stuck with the for loop. The for loop example has another inefficiency. Both newlist.append and word.upper are function references that are reevaluated each time through the loop.</q>
</p>
<p>

you should write instead:
<pre>
upper = str.upper
newlist = []
append = newlist.append
for word in oldlist:
    append(upper(word))
</pre>
</p><p>
This was a little bit surprising, and I received some emails questioning the validity of that optimization.
</p><p>
 First of all, the author of the Python performance tips suggest that we should always make test with our specific version of Python. I compared the previous two blocks of code in my laptop, by plotting the number of words vs time. Here are my results:
</p>
<img src='img/time.png'></img>
<p>
  <p>In this case, avoiding dots seems to be a good idea when working with big data, but you should make your own test.</p>

Another piece of advice is to learn about Threads and Multiprocess. Sometimes a simple:

<pre>
import threading
import concurrent.futures

n=#virtual cpus

with concurrent.futures.ProcessPoolExecutor(max_workers=n) as executor:
    executor.map(your_function, some_list_of_inputs) </pre> 
    will suffice. 
</p>

<p>You can find other advices, such as profiling, in  <a href='https://wiki.python.org/moin/PythonSpeed/PerformanceTips'> this link of Performance tips </a href>.
</p>
</article>

</body>

</html>
